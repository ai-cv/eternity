{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ew7HTbPpCJH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # Colab only\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import jieba\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import collections\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_path = '../../data/pos/'\n",
    "neg_path = '../../data/neg/'\n",
    "pos_list = os.listdir(pos_path)\n",
    "neg_list = os.listdir(neg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waimai_pos_1\n",
      "waimai_neg_1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pos_list[0]),print(neg_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 停用词词典\n",
    "stop_words = []\n",
    "# 读取停用词函数\n",
    "with open(\"../../data/stop_words_line.txt\", encoding=\"utf-8\") as st:\n",
    "    stop_words = st.readline().split(\" \")\n",
    "\n",
    "def delete_stop_words(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def str_strim(line):\n",
    "    new_line = re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）]+\", \"\", line)\n",
    "    return new_line.strip().strip().replace(\" \", \"\").replace(\"\\r\", \"\").replace(\"\\n\", \"\")\n",
    "\n",
    "def segment(line):\n",
    "    return delete_stop_words(jieba.cut(str_strim(line)))\n",
    "\n",
    "def read_data():\n",
    "    # 所有词\n",
    "    data = []\n",
    "    # 训练样本\n",
    "    train_data = []\n",
    "    label = []\n",
    "    for doc in pos_list:\n",
    "        with open(pos_path + doc, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                words = segment(line)\n",
    "                vector = []\n",
    "                for word in words:\n",
    "                    vector.append(word)\n",
    "                    data.append(word)\n",
    "                train_data.append(vector)\n",
    "                label.append(1)\n",
    "    for doc in neg_list:\n",
    "        with open(neg_path + doc, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                words = segment(line)\n",
    "                vector = []\n",
    "                for word in words:\n",
    "                    vector.append(word)\n",
    "                    data.append(word)\n",
    "                train_data.append(vector)\n",
    "                label.append(0)\n",
    "    return data,train_data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 1.496 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "89854"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, train_data_origin, train_label = read_data()\n",
    "data_size = len(data)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = [['哦', -1]]\n",
    "count.extend(collections.Counter(data).most_common(data_size - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('味道', 1583), ['哦', -1], -1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count[1],count[0],count[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {}\n",
    "for word, _ in count:\n",
    "    dictionary[word] = len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_num = []\n",
    "default_count = 0\n",
    "for word in data:\n",
    "    index = dictionary.get(word, 0)\n",
    "    # 默认\n",
    "    if index == 0:  \n",
    "        default_count += 1\n",
    "    train_data_num.append(index)\n",
    "count[0][1] = default_count\n",
    "reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_num = []\n",
    "default_count = 0\n",
    "for words in train_data_origin:\n",
    "    vector = []\n",
    "    for word in words:\n",
    "        index = dictionary.get(word, 0)\n",
    "        # 默认\n",
    "        if index == 0:  \n",
    "            default_count += 1\n",
    "        vector.append(index)\n",
    "    train_data_num.append(vector)\n",
    "count[0][1] = default_count\n",
    "reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([21, 2, 1, 4271], ['哦', 0], 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_num[0], count[0], dictionary.get('哦')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['哦', 0], ('味道', 1583), ('好吃', 1563), ('吃', 1542), ('送餐', 1541)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[21, 2, 1, 4271],\n",
       " [3066, 3066, 3066],\n",
       " [27],\n",
       " [2478, 1, 975, 2155, 316],\n",
       " [15, 1, 228, 4]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_num[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['很快', '好吃', '味道', '足量']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[reverse_dictionary[i] for i in train_data_num[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, list, int)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data_num),type(train_data_num[0]),type(train_data_num[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_data = keras.preprocessing.sequence.pad_sequences([[1,2],[4,6,7,8]],padding='post',maxlen=1024)\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data_num,padding='post',maxlen=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3066 3066 3066    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xpKOoWgu-llD",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 层按顺序堆叠以构建分类器：\n",
    "# 第一层是嵌入（Embedding）层。该层采用整数编码的词汇表，并查找每个词索引的嵌入向量（embedding vector）。这些向量是通过模型训练学习到的。向量向输出数组增加了一个维度。得到的维度为：(batch, sequence, embedding)。\n",
    "# 接下来，GlobalAveragePooling1D 将通过对序列维度求平均值来为每个样本返回一个定长输出向量。这允许模型以尽可能最简单的方式处理变长输入。\n",
    "# 该定长输出向量通过一个有 16 个隐层单元的全连接（Dense）层传输。\n",
    "# 最后一层与单个输出结点密集连接。使用 Sigmoid 激活函数，其函数值为介于 0 与 1 之间的浮点数，表示概率或置信度。\n",
    "# 输入形状是用于电影评论的词汇数目（10,000 词）\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(len(data), 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          1437664   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,437,953\n",
      "Trainable params: 1,437,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mr0GP-cQ-llN"
   },
   "outputs": [],
   "source": [
    "# 一个模型需要损失函数和优化器来进行训练。由于这是一个二分类问题且模型输出概率值（一个使用 sigmoid 激活函数的单一单元层），\n",
    "# 我们将使用 binary_crossentropy 损失函数。这不是损失函数的唯一选择，例如，您可以选择 mean_squared_error 。\n",
    "# 但是，一般来说 binary_crossentropy 更适合处理概率——它能够度量概率分布之间的“距离”，或者在我们的示例中，\n",
    "# 指的是度量 ground-truth 分布与预测值之间的“距离”。\n",
    "\n",
    "# 现在，配置模型来使用优化器和损失函数：\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = train_data.astype(np.int64)\n",
    "train_label = np.array(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11987, 11987)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data),len(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-NpcXY9--llS"
   },
   "outputs": [],
   "source": [
    "# 创建一个验证集\n",
    "train_size = 10000\n",
    "x_val = train_data[train_size:]\n",
    "y_val = train_label[train_size:]\n",
    "\n",
    "partial_x_train = train_data[:train_size]\n",
    "partial_y_train = train_label[:train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray, numpy.int32, numpy.ndarray, numpy.int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(partial_x_train), type(partial_x_train[0]), type(partial_x_train[0][0]),type(partial_y_train),type(partial_y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000, 1987, 1987)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(partial_x_train),len(partial_y_train),len(x_val),len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D6G9oqEV-Se-",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1987 samples\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 2s 213us/sample - loss: 0.6868 - accuracy: 0.6000 - val_loss: 0.6285 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 1s 66us/sample - loss: 0.6792 - accuracy: 0.6000 - val_loss: 0.5746 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 1s 70us/sample - loss: 0.6744 - accuracy: 0.6000 - val_loss: 0.5286 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 1s 73us/sample - loss: 0.6729 - accuracy: 0.6000 - val_loss: 0.5105 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 1s 74us/sample - loss: 0.6726 - accuracy: 0.6000 - val_loss: 0.5125 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 1s 72us/sample - loss: 0.6721 - accuracy: 0.6000 - val_loss: 0.5043 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 1s 73us/sample - loss: 0.6717 - accuracy: 0.6000 - val_loss: 0.5086 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 1s 75us/sample - loss: 0.6712 - accuracy: 0.6000 - val_loss: 0.5107 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 1s 73us/sample - loss: 0.6705 - accuracy: 0.6000 - val_loss: 0.5042 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 1s 72us/sample - loss: 0.6697 - accuracy: 0.6000 - val_loss: 0.5053 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 1s 71us/sample - loss: 0.6686 - accuracy: 0.6000 - val_loss: 0.5106 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 1s 74us/sample - loss: 0.6673 - accuracy: 0.6000 - val_loss: 0.5111 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 1s 73us/sample - loss: 0.6655 - accuracy: 0.6000 - val_loss: 0.5044 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 1s 73us/sample - loss: 0.6630 - accuracy: 0.6000 - val_loss: 0.5098 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 1s 79us/sample - loss: 0.6599 - accuracy: 0.6000 - val_loss: 0.4971 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 1s 74us/sample - loss: 0.6551 - accuracy: 0.6000 - val_loss: 0.5063 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 1s 77us/sample - loss: 0.6479 - accuracy: 0.6000 - val_loss: 0.4797 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 1s 81us/sample - loss: 0.6400 - accuracy: 0.6000 - val_loss: 0.4702 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 1s 79us/sample - loss: 0.6301 - accuracy: 0.6008 - val_loss: 0.4801 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 1s 83us/sample - loss: 0.6186 - accuracy: 0.6050 - val_loss: 0.4617 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 1s 86us/sample - loss: 0.6048 - accuracy: 0.6194 - val_loss: 0.4397 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 1s 81us/sample - loss: 0.5911 - accuracy: 0.6522 - val_loss: 0.4388 - val_accuracy: 0.9980\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 1s 76us/sample - loss: 0.5756 - accuracy: 0.6951 - val_loss: 0.4096 - val_accuracy: 0.9975\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 1s 88us/sample - loss: 0.5595 - accuracy: 0.7296 - val_loss: 0.4560 - val_accuracy: 0.9718\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 1s 88us/sample - loss: 0.5431 - accuracy: 0.7723 - val_loss: 0.4046 - val_accuracy: 0.9839\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 1s 85us/sample - loss: 0.5276 - accuracy: 0.7862 - val_loss: 0.4118 - val_accuracy: 0.9602\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 1s 81us/sample - loss: 0.5109 - accuracy: 0.8112 - val_loss: 0.4282 - val_accuracy: 0.9331\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 1s 82us/sample - loss: 0.4963 - accuracy: 0.8229 - val_loss: 0.4111 - val_accuracy: 0.9311\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 1s 75us/sample - loss: 0.4812 - accuracy: 0.8383 - val_loss: 0.3997 - val_accuracy: 0.9240\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 1s 79us/sample - loss: 0.4669 - accuracy: 0.8411 - val_loss: 0.3784 - val_accuracy: 0.9290\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 1s 74us/sample - loss: 0.4532 - accuracy: 0.8502 - val_loss: 0.3700 - val_accuracy: 0.9235\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 1s 73us/sample - loss: 0.4411 - accuracy: 0.8523 - val_loss: 0.3863 - val_accuracy: 0.8983\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 1s 72us/sample - loss: 0.4285 - accuracy: 0.8553 - val_loss: 0.3543 - val_accuracy: 0.9165\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 1s 83us/sample - loss: 0.4172 - accuracy: 0.8583 - val_loss: 0.3400 - val_accuracy: 0.9175\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 1s 77us/sample - loss: 0.4063 - accuracy: 0.8609 - val_loss: 0.3659 - val_accuracy: 0.8848\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 1s 73us/sample - loss: 0.3958 - accuracy: 0.8659 - val_loss: 0.3423 - val_accuracy: 0.9024\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 1s 81us/sample - loss: 0.3864 - accuracy: 0.8653 - val_loss: 0.3228 - val_accuracy: 0.9099\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 1s 80us/sample - loss: 0.3775 - accuracy: 0.8677 - val_loss: 0.3430 - val_accuracy: 0.8903\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 1s 82us/sample - loss: 0.3688 - accuracy: 0.8677 - val_loss: 0.2908 - val_accuracy: 0.9215\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 1s 88us/sample - loss: 0.3615 - accuracy: 0.8708 - val_loss: 0.3532 - val_accuracy: 0.8616\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 1s 86us/sample - loss: 0.3540 - accuracy: 0.8738 - val_loss: 0.2895 - val_accuracy: 0.9114\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 1s 88us/sample - loss: 0.3481 - accuracy: 0.8742 - val_loss: 0.3281 - val_accuracy: 0.8807\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 1s 82us/sample - loss: 0.3408 - accuracy: 0.8760 - val_loss: 0.2886 - val_accuracy: 0.9089\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 1s 91us/sample - loss: 0.3359 - accuracy: 0.8747 - val_loss: 0.3056 - val_accuracy: 0.8943\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 1s 94us/sample - loss: 0.3298 - accuracy: 0.8803 - val_loss: 0.3169 - val_accuracy: 0.8797\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 1s 83us/sample - loss: 0.3251 - accuracy: 0.8811 - val_loss: 0.3117 - val_accuracy: 0.8853\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 1s 80us/sample - loss: 0.3197 - accuracy: 0.8829 - val_loss: 0.2974 - val_accuracy: 0.8923\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 1s 83us/sample - loss: 0.3152 - accuracy: 0.8851 - val_loss: 0.2946 - val_accuracy: 0.8913\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 1s 93us/sample - loss: 0.3108 - accuracy: 0.8854 - val_loss: 0.2618 - val_accuracy: 0.9139\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 1s 88us/sample - loss: 0.3074 - accuracy: 0.8866 - val_loss: 0.3206 - val_accuracy: 0.8707\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 1s 88us/sample - loss: 0.3042 - accuracy: 0.8862 - val_loss: 0.2448 - val_accuracy: 0.9205\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 1s 88us/sample - loss: 0.3002 - accuracy: 0.8891 - val_loss: 0.3535 - val_accuracy: 0.8455\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 1s 80us/sample - loss: 0.2977 - accuracy: 0.8898 - val_loss: 0.2607 - val_accuracy: 0.9069\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 1s 75us/sample - loss: 0.2929 - accuracy: 0.8912 - val_loss: 0.2937 - val_accuracy: 0.8878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 1s 78us/sample - loss: 0.2891 - accuracy: 0.8941 - val_loss: 0.2582 - val_accuracy: 0.9079\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 1s 94us/sample - loss: 0.2870 - accuracy: 0.8941 - val_loss: 0.3235 - val_accuracy: 0.8641\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 1s 84us/sample - loss: 0.2843 - accuracy: 0.8943 - val_loss: 0.2598 - val_accuracy: 0.9064\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 1s 76us/sample - loss: 0.2803 - accuracy: 0.8954 - val_loss: 0.3266 - val_accuracy: 0.8616\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 1s 80us/sample - loss: 0.2788 - accuracy: 0.8967 - val_loss: 0.2654 - val_accuracy: 0.9034\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 1s 90us/sample - loss: 0.2765 - accuracy: 0.8981 - val_loss: 0.3038 - val_accuracy: 0.8752\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 1s 87us/sample - loss: 0.2737 - accuracy: 0.8984 - val_loss: 0.2875 - val_accuracy: 0.8868\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 1s 93us/sample - loss: 0.2698 - accuracy: 0.9007 - val_loss: 0.3049 - val_accuracy: 0.8732\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 1s 88us/sample - loss: 0.2692 - accuracy: 0.8987 - val_loss: 0.2483 - val_accuracy: 0.9074\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 1s 90us/sample - loss: 0.2655 - accuracy: 0.9027 - val_loss: 0.2995 - val_accuracy: 0.8762\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.2635 - accuracy: 0.9029 - val_loss: 0.3019 - val_accuracy: 0.8732\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 1s 81us/sample - loss: 0.2610 - accuracy: 0.9036 - val_loss: 0.2473 - val_accuracy: 0.9079\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 1s 73us/sample - loss: 0.2592 - accuracy: 0.9038 - val_loss: 0.2716 - val_accuracy: 0.8958\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 1s 91us/sample - loss: 0.2577 - accuracy: 0.9042 - val_loss: 0.2459 - val_accuracy: 0.9079\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 1s 95us/sample - loss: 0.2571 - accuracy: 0.9039 - val_loss: 0.3001 - val_accuracy: 0.8717\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 1s 92us/sample - loss: 0.2531 - accuracy: 0.9063 - val_loss: 0.2738 - val_accuracy: 0.8933\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 0.2517 - accuracy: 0.9062 - val_loss: 0.2908 - val_accuracy: 0.8772\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.2489 - accuracy: 0.9082 - val_loss: 0.2696 - val_accuracy: 0.8968\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 1s 119us/sample - loss: 0.2474 - accuracy: 0.9082 - val_loss: 0.2845 - val_accuracy: 0.8853\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 1s 94us/sample - loss: 0.2462 - accuracy: 0.9062 - val_loss: 0.2815 - val_accuracy: 0.8878\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.2443 - accuracy: 0.9092 - val_loss: 0.2174 - val_accuracy: 0.9195\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 0.2446 - accuracy: 0.9079 - val_loss: 0.2990 - val_accuracy: 0.8727\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 1s 88us/sample - loss: 0.2400 - accuracy: 0.9111 - val_loss: 0.2565 - val_accuracy: 0.9039\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 1s 85us/sample - loss: 0.2386 - accuracy: 0.9121 - val_loss: 0.2762 - val_accuracy: 0.8918\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 1s 85us/sample - loss: 0.2378 - accuracy: 0.9111 - val_loss: 0.2968 - val_accuracy: 0.8732\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 1s 75us/sample - loss: 0.2358 - accuracy: 0.9111 - val_loss: 0.2482 - val_accuracy: 0.9069\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 1s 75us/sample - loss: 0.2334 - accuracy: 0.9138 - val_loss: 0.2446 - val_accuracy: 0.9074\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 1s 88us/sample - loss: 0.2319 - accuracy: 0.9138 - val_loss: 0.2759 - val_accuracy: 0.8923\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 1s 88us/sample - loss: 0.2304 - accuracy: 0.9152 - val_loss: 0.2690 - val_accuracy: 0.8953\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 1s 83us/sample - loss: 0.2288 - accuracy: 0.9156 - val_loss: 0.3044 - val_accuracy: 0.8717\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 1s 74us/sample - loss: 0.2283 - accuracy: 0.9156 - val_loss: 0.2988 - val_accuracy: 0.8772\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 1s 79us/sample - loss: 0.2270 - accuracy: 0.9152 - val_loss: 0.2275 - val_accuracy: 0.9144\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 1s 75us/sample - loss: 0.2254 - accuracy: 0.9158 - val_loss: 0.2858 - val_accuracy: 0.8822\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 1s 77us/sample - loss: 0.2229 - accuracy: 0.9165 - val_loss: 0.2905 - val_accuracy: 0.8802\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 1s 73us/sample - loss: 0.2222 - accuracy: 0.9180 - val_loss: 0.2322 - val_accuracy: 0.9134\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 1s 71us/sample - loss: 0.2216 - accuracy: 0.9175 - val_loss: 0.2816 - val_accuracy: 0.8883\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 1s 74us/sample - loss: 0.2194 - accuracy: 0.9192 - val_loss: 0.2670 - val_accuracy: 0.8953\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 1s 70us/sample - loss: 0.2183 - accuracy: 0.9193 - val_loss: 0.2927 - val_accuracy: 0.8782\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 1s 79us/sample - loss: 0.2167 - accuracy: 0.9206 - val_loss: 0.2921 - val_accuracy: 0.8782\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 1s 78us/sample - loss: 0.2163 - accuracy: 0.9204 - val_loss: 0.2247 - val_accuracy: 0.9170\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 1s 70us/sample - loss: 0.2151 - accuracy: 0.9213 - val_loss: 0.3034 - val_accuracy: 0.8737\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 1s 75us/sample - loss: 0.2127 - accuracy: 0.9218 - val_loss: 0.2951 - val_accuracy: 0.8762\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 1s 71us/sample - loss: 0.2122 - accuracy: 0.9214 - val_loss: 0.2278 - val_accuracy: 0.9139\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 1s 72us/sample - loss: 0.2118 - accuracy: 0.9212 - val_loss: 0.3244 - val_accuracy: 0.8626\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 1s 72us/sample - loss: 0.2104 - accuracy: 0.9235 - val_loss: 0.2462 - val_accuracy: 0.9069\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 1s 76us/sample - loss: 0.2084 - accuracy: 0.9231 - val_loss: 0.2592 - val_accuracy: 0.9014\n"
     ]
    }
   ],
   "source": [
    "# 训练模型¶\n",
    "# 以 512 个样本的 mini-batch 大小迭代 40 个 epoch 来训练模型。这是指对 x_train 和 y_train 张量中所有样本的的 40 次迭代。\n",
    "# 在训练过程中，监测来自验证集的 10,000 个样本上的损失值（loss）和准确率（accuracy）：\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================word2vec======================\n",
    "# e = model.layers[0]\n",
    "# weights = e.get_weights()[0]\n",
    "# print(weights.shape) # shape: (vocab_size, embedding_dim)\n",
    "\n",
    "# print_i = 0\n",
    "\n",
    "# for word,num in words_dict.items():\n",
    "#     print_i += print_i\n",
    "#     if print_i > 10:\n",
    "#         break\n",
    "#     vec = weights[num+1] # skip 0, it's padding.\n",
    "#     print(word + ':' + ' '.join([str(x) for x in vec]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zOMKywn4zReN",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11987/1 - 1s - loss: 0.5255 - accuracy: 0.9193\n",
      "[0.21596541645986936, 0.9193293]\n"
     ]
    }
   ],
   "source": [
    "# 评估模型\n",
    "# 模型性能 将返回两个值。损失值（loss）（一个表示误差的数字，值越低越好）与准确率（accuracy）。\n",
    "results = model.evaluate(train_data,  train_label, verbose=2)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VcvSXvhp-llb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit() 返回一个 History 对象，该对象包含一个字典，其中包含训练阶段所发生的一切事件\n",
    "# 有四个条目：在训练和验证期间，每个条目对应一个监控指标。我们可以使用这些条目来绘制训练与验证过程的损失值（loss）和准确率（accuracy），以便进行比较。\n",
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nGoYf2Js-lle"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 创建一个准确率（accuracy）和损失值（loss）随时间变化的图表\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# “bo”代表 \"蓝点\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b代表“蓝色实线”\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6hXx-xOv-llh"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 在该图中，点代表训练损失值（loss）与准确率（accuracy），实线代表验证损失值（loss）与准确率（accuracy）。\n",
    "\n",
    "# 注意训练损失值随每一个 epoch 下降而训练准确率（accuracy）随每一个 epoch 上升。这在使用梯度下降优化时是可预期的——理应在每次迭代中最小化期望值。\n",
    "\n",
    "# 验证过程的损失值（loss）与准确率（accuracy）的情况却并非如此——它们似乎在 20 个 epoch 后达到峰值。这是过拟合的一个实例：模型在训练数据上的表现比在以前从未见过的数据上的表现要更好。在此之后，模型过度优化并学习特定于训练数据的表示，而不能够泛化到测试数据。\n",
    "\n",
    "# 对于这种特殊情况，我们可以通过在 20 个左右的 epoch 后停止训练来避免过拟合。稍后，您将看到如何通过回调自动执行此操作。\n",
    "plt.clf()   # 清除数字\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "text_classification.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
