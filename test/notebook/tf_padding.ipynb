{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ew7HTbPpCJH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # Colab only\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_path = '../data/pos/'\n",
    "neg_path = '../data/neg/'\n",
    "pos_list = os.listdir(pos_path)\n",
    "neg_list = os.listdir(neg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_label = []\n",
    "for doc in pos_list:\n",
    "    with open(pos_path + doc, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            train_data.append(line)\n",
    "            train_label.append(1)\n",
    "            \n",
    "for doc in neg_list:\n",
    "    with open(neg_path + doc, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            train_data.append(line)\n",
    "            train_label.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zXXx5Oc3pOmN",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imdb = keras.datasets.imdb\n",
    "# (train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=100)\n",
    "train_data = []\n",
    "train_labels = []\n",
    "with open(\"../data/demo.txt\", \"r\", encoding=\"utf-8\") as lines:\n",
    "    for line in lines.readlines():\n",
    "        words = line.split(\",\")\n",
    "        train_labels.append(np.int64(int(words[0])))\n",
    "#         train_data.append(np.array(words[1].split(\" \")))\n",
    "        train_data.append(np.array(keras.preprocessing.text.one_hot(words[1], 100)))\n",
    "train_data = np.array(train_data)\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray, numpy.int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data), type(train_data[0]), type(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " type(train_labels),type(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y8qCnve_-lkO",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training entries: 50, labels: 50\n"
     ]
    }
   ],
   "source": [
    "print(\"Training entries: {}, labels: {}\".format(len(train_data), len(train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26  7 91 89  7 91 77 78  1 21  8 96 95 17  8 91 71 98 35 71 96 20 41  4\n",
      " 64  7 40 91 33 18 90 66 70 37 27 99 25 61 81 82 67 96 82 62 47 49 25 59\n",
      "  3 18 47 13 86 29  4  1 77 78 11  7 96 37 22 25  9 34 79  7 91 70 61 37\n",
      " 25]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "USSSBnkE-lky"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0]), len(train_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lFP_XKVRp4_S"
   },
   "source": [
    "## 准备数据\n",
    "\n",
    "影评——即整数数组必须在输入神经网络之前转换为张量。这种转换可以通过以下两种方式来完成：\n",
    "\n",
    "* 将数组转换为表示单词出现与否的由 0 和 1 组成的向量，类似于 one-hot 编码。例如，序列[3, 5]将转换为一个 10,000 维的向量，该向量除了索引为 3 和 5 的位置是 1 以外，其他都为 0。然后，将其作为网络的首层——一个可以处理浮点型向量数据的稠密层。不过，这种方法需要大量的内存，需要一个大小为 `num_words * num_reviews` 的矩阵。\n",
    "\n",
    "* 或者，我们可以填充数组来保证输入数据具有相同的长度，然后创建一个大小为 `max_length * num_reviews` 的整型张量。我们可以使用能够处理此形状数据的嵌入层作为网络中的第一层。\n",
    "\n",
    "在本教程中，我们将使用第二种方法。\n",
    "\n",
    "由于电影评论长度必须相同，我们将使用 [pad_sequences](https://tensorflow.google.cn/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences) 函数来使长度标准化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
    "                                                        dtype='str',\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9' '8' '1' '7' '9' '8' '3' '7' '7' '1' '2' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0']\n"
     ]
    }
   ],
   "source": [
    "print(train_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLC02j2g-llC"
   },
   "source": [
    "## 构建模型\n",
    "\n",
    "神经网络由堆叠的层来构建，这需要从两个主要方面来进行体系结构决策：\n",
    "\n",
    "* 模型里有多少层？\n",
    "* 每个层里有多少*隐层单元（hidden units）*？\n",
    "\n",
    "在此样本中，输入数据包含一个单词索引的数组。要预测的标签为 0 或 1。让我们来为该问题构建一个模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xpKOoWgu-llD",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          1600      \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,889\n",
      "Trainable params: 1,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 输入形状是用于电影评论的词汇数目（10,000 词）\n",
    "vocab_size = 100\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6PbKQ6mucuKL"
   },
   "source": [
    "层按顺序堆叠以构建分类器：\n",
    "\n",
    "1. 第一层是`嵌入（Embedding）`层。该层采用整数编码的词汇表，并查找每个词索引的嵌入向量（embedding vector）。这些向量是通过模型训练学习到的。向量向输出数组增加了一个维度。得到的维度为：`(batch, sequence, embedding)`。\n",
    "2. 接下来，`GlobalAveragePooling1D` 将通过对序列维度求平均值来为每个样本返回一个定长输出向量。这允许模型以尽可能最简单的方式处理变长输入。\n",
    "3. 该定长输出向量通过一个有 16 个隐层单元的全连接（`Dense`）层传输。\n",
    "4. 最后一层与单个输出结点密集连接。使用 `Sigmoid` 激活函数，其函数值为介于 0 与 1 之间的浮点数，表示概率或置信度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0XMwnDOp-llH"
   },
   "source": [
    "### 隐层单元\n",
    "\n",
    "上述模型在输入输出之间有两个中间层或“隐藏层”。输出（单元，结点或神经元）的数量即为层表示空间的维度。换句话说，是学习内部表示时网络所允许的自由度。\n",
    "\n",
    "如果模型具有更多的隐层单元（更高维度的表示空间）和/或更多层，则可以学习到更复杂的表示。但是，这会使网络的计算成本更高，并且可能导致学习到不需要的模式——一些能够在训练数据上而不是测试数据上改善性能的模式。这被称为*过拟合（overfitting）*，我们稍后会对此进行探究。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L4EqVWg4-llM"
   },
   "source": [
    "### 损失函数与优化器\n",
    "\n",
    "一个模型需要损失函数和优化器来进行训练。由于这是一个二分类问题且模型输出概率值（一个使用 sigmoid 激活函数的单一单元层），我们将使用 `binary_crossentropy` 损失函数。\n",
    "\n",
    "这不是损失函数的唯一选择，例如，您可以选择 `mean_squared_error` 。但是，一般来说 `binary_crossentropy` 更适合处理概率——它能够度量概率分布之间的“距离”，或者在我们的示例中，指的是度量 ground-truth 分布与预测值之间的“距离”。\n",
    "\n",
    "稍后，当我们研究回归问题（例如，预测房价）时，我们将介绍如何使用另一种叫做均方误差的损失函数。\n",
    "\n",
    "现在，配置模型来使用优化器和损失函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mr0GP-cQ-llN"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hCWYwkug-llQ"
   },
   "source": [
    "## 创建一个验证集\n",
    "\n",
    "在训练时，我们想要检查模型在未见过的数据上的准确率（accuracy）。通过从原始训练数据中分离 10,000 个样本来创建一个*验证集*。（为什么现在不使用测试集？我们的目标是只使用训练数据来开发和调整模型，然后只使用一次测试数据来评估准确率（accuracy））。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = train_data.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-NpcXY9--llS"
   },
   "outputs": [],
   "source": [
    "train_size = 20\n",
    "x_val = train_data[:train_size]\n",
    "partial_x_train = train_data[train_size:]\n",
    "\n",
    "y_val = train_labels[:train_size]\n",
    "partial_y_train = train_labels[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "35jv_fzP-llU"
   },
   "source": [
    "## 训练模型\n",
    "\n",
    "以 512 个样本的 mini-batch 大小迭代 40 个 epoch 来训练模型。这是指对 `x_train` 和 `y_train` 张量中所有样本的的 40 次迭代。在训练过程中，监测来自验证集的 10,000 个样本上的损失值（loss）和准确率（accuracy）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray, numpy.int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(partial_x_train), type(partial_x_train[0]), type(partial_x_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(partial_y_train),type(partial_y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray, numpy.int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_val), type(x_val[0]), type(x_val[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_val),type(y_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D6G9oqEV-Se-",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30 samples, validate on 20 samples\n",
      "Epoch 1/40\n",
      "30/30 [==============================] - 1s 26ms/sample - loss: 0.6919 - accuracy: 0.6000 - val_loss: 0.6952 - val_accuracy: 0.4000\n",
      "Epoch 2/40\n",
      "30/30 [==============================] - 0s 408us/sample - loss: 0.6913 - accuracy: 0.6000 - val_loss: 0.6958 - val_accuracy: 0.4000\n",
      "Epoch 3/40\n",
      "30/30 [==============================] - 0s 500us/sample - loss: 0.6907 - accuracy: 0.6000 - val_loss: 0.6965 - val_accuracy: 0.4000\n",
      "Epoch 4/40\n",
      "30/30 [==============================] - 0s 556us/sample - loss: 0.6902 - accuracy: 0.6000 - val_loss: 0.6971 - val_accuracy: 0.4000\n",
      "Epoch 5/40\n",
      "30/30 [==============================] - 0s 581us/sample - loss: 0.6896 - accuracy: 0.6000 - val_loss: 0.6978 - val_accuracy: 0.4000\n",
      "Epoch 6/40\n",
      "30/30 [==============================] - 0s 532us/sample - loss: 0.6891 - accuracy: 0.6000 - val_loss: 0.6984 - val_accuracy: 0.4000\n",
      "Epoch 7/40\n",
      "30/30 [==============================] - 0s 510us/sample - loss: 0.6887 - accuracy: 0.6000 - val_loss: 0.6990 - val_accuracy: 0.4000\n",
      "Epoch 8/40\n",
      "30/30 [==============================] - 0s 590us/sample - loss: 0.6882 - accuracy: 0.6000 - val_loss: 0.6996 - val_accuracy: 0.4000\n",
      "Epoch 9/40\n",
      "30/30 [==============================] - 0s 586us/sample - loss: 0.6878 - accuracy: 0.6000 - val_loss: 0.7002 - val_accuracy: 0.4000\n",
      "Epoch 10/40\n",
      "30/30 [==============================] - 0s 486us/sample - loss: 0.6873 - accuracy: 0.6000 - val_loss: 0.7008 - val_accuracy: 0.4000\n",
      "Epoch 11/40\n",
      "30/30 [==============================] - 0s 617us/sample - loss: 0.6869 - accuracy: 0.6000 - val_loss: 0.7015 - val_accuracy: 0.4000\n",
      "Epoch 12/40\n",
      "30/30 [==============================] - 0s 551us/sample - loss: 0.6864 - accuracy: 0.6000 - val_loss: 0.7021 - val_accuracy: 0.4000\n",
      "Epoch 13/40\n",
      "30/30 [==============================] - 0s 554us/sample - loss: 0.6860 - accuracy: 0.6000 - val_loss: 0.7028 - val_accuracy: 0.4000\n",
      "Epoch 14/40\n",
      "30/30 [==============================] - 0s 716us/sample - loss: 0.6855 - accuracy: 0.6000 - val_loss: 0.7035 - val_accuracy: 0.4000\n",
      "Epoch 15/40\n",
      "30/30 [==============================] - 0s 575us/sample - loss: 0.6851 - accuracy: 0.6000 - val_loss: 0.7043 - val_accuracy: 0.4000\n",
      "Epoch 16/40\n",
      "30/30 [==============================] - 0s 547us/sample - loss: 0.6846 - accuracy: 0.6000 - val_loss: 0.7050 - val_accuracy: 0.4000\n",
      "Epoch 17/40\n",
      "30/30 [==============================] - 0s 548us/sample - loss: 0.6842 - accuracy: 0.6000 - val_loss: 0.7058 - val_accuracy: 0.4000\n",
      "Epoch 18/40\n",
      "30/30 [==============================] - 0s 561us/sample - loss: 0.6837 - accuracy: 0.6000 - val_loss: 0.7065 - val_accuracy: 0.4000\n",
      "Epoch 19/40\n",
      "30/30 [==============================] - 0s 495us/sample - loss: 0.6833 - accuracy: 0.6000 - val_loss: 0.7073 - val_accuracy: 0.4000\n",
      "Epoch 20/40\n",
      "30/30 [==============================] - 0s 528us/sample - loss: 0.6829 - accuracy: 0.6000 - val_loss: 0.7081 - val_accuracy: 0.4000\n",
      "Epoch 21/40\n",
      "30/30 [==============================] - 0s 511us/sample - loss: 0.6825 - accuracy: 0.6000 - val_loss: 0.7089 - val_accuracy: 0.4000\n",
      "Epoch 22/40\n",
      "30/30 [==============================] - 0s 513us/sample - loss: 0.6821 - accuracy: 0.6000 - val_loss: 0.7097 - val_accuracy: 0.4000\n",
      "Epoch 23/40\n",
      "30/30 [==============================] - 0s 615us/sample - loss: 0.6817 - accuracy: 0.6000 - val_loss: 0.7106 - val_accuracy: 0.4000\n",
      "Epoch 24/40\n",
      "30/30 [==============================] - 0s 527us/sample - loss: 0.6813 - accuracy: 0.6000 - val_loss: 0.7114 - val_accuracy: 0.4000\n",
      "Epoch 25/40\n",
      "30/30 [==============================] - 0s 610us/sample - loss: 0.6809 - accuracy: 0.6000 - val_loss: 0.7123 - val_accuracy: 0.4000\n",
      "Epoch 26/40\n",
      "30/30 [==============================] - 0s 538us/sample - loss: 0.6805 - accuracy: 0.6000 - val_loss: 0.7131 - val_accuracy: 0.4000\n",
      "Epoch 27/40\n",
      "30/30 [==============================] - 0s 520us/sample - loss: 0.6802 - accuracy: 0.6000 - val_loss: 0.7140 - val_accuracy: 0.4000\n",
      "Epoch 28/40\n",
      "30/30 [==============================] - 0s 531us/sample - loss: 0.6798 - accuracy: 0.6000 - val_loss: 0.7149 - val_accuracy: 0.4000\n",
      "Epoch 29/40\n",
      "30/30 [==============================] - 0s 551us/sample - loss: 0.6794 - accuracy: 0.6000 - val_loss: 0.7158 - val_accuracy: 0.4000\n",
      "Epoch 30/40\n",
      "30/30 [==============================] - 0s 540us/sample - loss: 0.6791 - accuracy: 0.6000 - val_loss: 0.7167 - val_accuracy: 0.4000\n",
      "Epoch 31/40\n",
      "30/30 [==============================] - 0s 548us/sample - loss: 0.6788 - accuracy: 0.6000 - val_loss: 0.7177 - val_accuracy: 0.4000\n",
      "Epoch 32/40\n",
      "30/30 [==============================] - 0s 530us/sample - loss: 0.6784 - accuracy: 0.6000 - val_loss: 0.7186 - val_accuracy: 0.4000\n",
      "Epoch 33/40\n",
      "30/30 [==============================] - 0s 527us/sample - loss: 0.6781 - accuracy: 0.6000 - val_loss: 0.7195 - val_accuracy: 0.4000\n",
      "Epoch 34/40\n",
      "30/30 [==============================] - 0s 523us/sample - loss: 0.6778 - accuracy: 0.6000 - val_loss: 0.7205 - val_accuracy: 0.4000\n",
      "Epoch 35/40\n",
      "30/30 [==============================] - 0s 510us/sample - loss: 0.6775 - accuracy: 0.6000 - val_loss: 0.7215 - val_accuracy: 0.4000\n",
      "Epoch 36/40\n",
      "30/30 [==============================] - 0s 524us/sample - loss: 0.6772 - accuracy: 0.6000 - val_loss: 0.7225 - val_accuracy: 0.4000\n",
      "Epoch 37/40\n",
      "30/30 [==============================] - 0s 513us/sample - loss: 0.6769 - accuracy: 0.6000 - val_loss: 0.7235 - val_accuracy: 0.4000\n",
      "Epoch 38/40\n",
      "30/30 [==============================] - 0s 522us/sample - loss: 0.6767 - accuracy: 0.6000 - val_loss: 0.7245 - val_accuracy: 0.4000\n",
      "Epoch 39/40\n",
      "30/30 [==============================] - 0s 521us/sample - loss: 0.6764 - accuracy: 0.6000 - val_loss: 0.7255 - val_accuracy: 0.4000\n",
      "Epoch 40/40\n",
      "30/30 [==============================] - 0s 525us/sample - loss: 0.6762 - accuracy: 0.6000 - val_loss: 0.7266 - val_accuracy: 0.4000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9EEGuDVuzb5r"
   },
   "source": [
    "## 评估模型\n",
    "\n",
    "我们来看一下模型的性能如何。将返回两个值。损失值（loss）（一个表示误差的数字，值越低越好）与准确率（accuracy）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zOMKywn4zReN",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/1 - 0s - loss: 0.6706 - accuracy: 0.5200\n",
      "[0.6961713790893554, 0.52]\n"
     ]
    }
   ],
   "source": [
    "# results = model.evaluate(test_data,  test_labels, verbose=2)\n",
    "# print(results)\n",
    "results = model.evaluate(train_data,  train_labels, verbose=2)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z1iEXVTR0Z2t"
   },
   "source": [
    "这种十分朴素的方法得到了约 87% 的准确率（accuracy）。若采用更好的方法，模型的准确率应当接近 95%。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5KggXVeL-llZ"
   },
   "source": [
    "## 创建一个准确率（accuracy）和损失值（loss）随时间变化的图表\n",
    "\n",
    "`model.fit()` 返回一个 `History` 对象，该对象包含一个字典，其中包含训练阶段所发生的一切事件："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VcvSXvhp-llb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'loss', 'accuracy', 'val_accuracy'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nRKsqL40-lle"
   },
   "source": [
    "有四个条目：在训练和验证期间，每个条目对应一个监控指标。我们可以使用这些条目来绘制训练与验证过程的损失值（loss）和准确率（accuracy），以便进行比较。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nGoYf2Js-lle"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# “bo”代表 \"蓝点\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b代表“蓝色实线”\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6hXx-xOv-llh"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 清除数字\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oFEmZ5zq-llk"
   },
   "source": [
    "\n",
    "在该图中，点代表训练损失值（loss）与准确率（accuracy），实线代表验证损失值（loss）与准确率（accuracy）。\n",
    "\n",
    "注意训练损失值随每一个 epoch *下降*而训练准确率（accuracy）随每一个 epoch *上升*。这在使用梯度下降优化时是可预期的——理应在每次迭代中最小化期望值。\n",
    "\n",
    "验证过程的损失值（loss）与准确率（accuracy）的情况却并非如此——它们似乎在 20 个 epoch 后达到峰值。这是过拟合的一个实例：模型在训练数据上的表现比在以前从未见过的数据上的表现要更好。在此之后，模型过度优化并学习*特定*于训练数据的表示，而不能够*泛化*到测试数据。\n",
    "\n",
    "对于这种特殊情况，我们可以通过在 20 个左右的 epoch 后停止训练来避免过拟合。稍后，您将看到如何通过回调自动执行此操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "text_classification.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
